{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Context\n",
    "\n",
    "L’entreprise pharmaceutique HumanForYou, située en Inde, emploie environ 4 000 personnes mais doit faire face à un taux de turn-over annuel de 15%, impactant son fonctionnement de plusieurs manières :\n",
    "\n",
    "- Retards de projets nuisibles à la réputation de l’entreprise auprès des clients et partenaires.\n",
    "- Charge importante sur les ressources humaines, nécessitant un service conséquent pour recruter de nouveaux talents.\n",
    "- Perte de productivité en raison du temps nécessaire à la formation et à l’intégration des nouveaux employés.\n",
    "- L’objectif est de comprendre les facteurs clés influençant ce taux de turn-over et de proposer des modèles prédictifs et des stratégies concrètes pour réduire ce phénomène.\n",
    "\n",
    "les etapes du projet : Données brutes > Données structurés (Catégorielle & Numérique) > input > Deeplearning / AI > produit (^y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Environement setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nbformat\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "csv_path = \"./csv/\"\n",
    "\n",
    "# Load datasets\n",
    "in_time = pd.read_csv(csv_path + \"in_time.csv\")\n",
    "out_time = pd.read_csv(csv_path + \"out_time.csv\")\n",
    "general_data = pd.read_csv(csv_path + \"general_data.csv\")\n",
    "manager_survey_data = pd.read_csv(csv_path + \"manager_survey_data.csv\")\n",
    "employee_survey_data = pd.read_csv(csv_path + \"employee_survey_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Data mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time mixing\n",
    "total_time = pd.concat([in_time, out_time], ignore_index=True)\n",
    "total_time = total_time.replace(np.nan, 0)\n",
    "total_time.iloc[:, 1:] = total_time.iloc[:, 1:].apply(pd.to_datetime, errors='coerce')\n",
    "total_time = total_time.diff(periods=4410, axis=0)\n",
    "total_time = total_time.iloc[4410:]\n",
    "total_time.reset_index(inplace=True)\n",
    "total_time.drop(\n",
    "    columns=[\n",
    "            'Unnamed: 0', '2015-01-01', '2015-01-14','2015-01-26','2015-03-05',\n",
    "            '2015-05-01','2015-07-17','2015-09-17','2015-10-02',\n",
    "            '2015-11-09','2015-11-10','2015-11-11','2015-12-25', 'index'\n",
    "            ],\n",
    "    axis=1,\n",
    "    inplace=True\n",
    ")\n",
    "total_time = total_time.replace(pd.NaT, pd.Timedelta(0))\n",
    "total_time['Mean Time']=total_time.mean(axis=1)\n",
    "total_time['hrs']=total_time['Mean Time'] / np.timedelta64(1, 'h')\n",
    "total_time.reset_index(inplace=True)\n",
    "total_time.drop(total_time.columns.difference(['index','hrs']), axis=1, inplace=True)\n",
    "total_time.rename(columns={'index': 'EmployeeID'}, inplace=True)\n",
    "\n",
    "total_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create global dataframe\n",
    "global_data = pd.merge(general_data, total_time, on='EmployeeID', how='inner')\n",
    "global_data = pd.merge(global_data, manager_survey_data, on='EmployeeID', how='inner')\n",
    "global_data = pd.merge(global_data, employee_survey_data, on='EmployeeID', how='inner')\n",
    "\n",
    "global_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Remove unusable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unique value column\n",
    "for col in global_data.columns:\n",
    "    if len(global_data[col].unique()) == 1:\n",
    "        global_data.drop(columns=[col], axis=1, inplace=True)\n",
    "        print(\"Deleted : \" + col + \" (Only one value)\")\n",
    "\n",
    "# Delete Ethical column\n",
    "global_data.drop(columns=['Age', 'EmployeeID', 'Gender', 'MaritalStatus'], axis=1, inplace=True)\n",
    "\n",
    "global_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Change column type for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data['Education'] = global_data['Education'].astype('object')\n",
    "global_data['EnvironmentSatisfaction'] = global_data['EnvironmentSatisfaction'].astype('object')\n",
    "global_data['JobInvolvement'] = global_data['JobInvolvement'].astype('object')\n",
    "global_data['JobSatisfaction'] = global_data['JobSatisfaction'].astype('object')\n",
    "global_data['PerformanceRating'] = global_data['PerformanceRating'].astype('object')\n",
    "global_data['JobLevel'] = global_data['JobLevel'].astype('object')\n",
    "global_data['WorkLifeBalance'] = global_data['WorkLifeBalance'].astype('object')\n",
    "\n",
    "global_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Replace data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace numerical data\n",
    "for col in global_data.columns:\n",
    "    if global_data[col].isna().values.any():\n",
    "        global_data[col].fillna(global_data[col].median(), inplace=True)\n",
    "\n",
    "# Replace categorical data\n",
    "global_data['Education'].replace({1: 'BAC', 2: 'BAC+2', 3: 'BAC+3', 4: 'BAC+5', 5: 'Doctorat'}, inplace=True)\n",
    "global_data['JobInvolvement'].replace({1: 'Faible', 2: 'Moyenne', 3: 'Importante', 4: 'Très importante'}, inplace=True)\n",
    "global_data['PerformanceRating'].replace({1: 'Faible', 2: 'Bon', 3: 'Excellent', 4: 'Au delà des attentes'}, inplace=True)\n",
    "global_data['EnvironmentSatisfaction'].replace({1: 'Faible', 2: 'Moyen', 3: 'Élevé', 4: 'Très élevé'}, inplace=True)\n",
    "global_data['JobSatisfaction'].replace({1: 'Faible', 2: 'Moyen', 3: 'Élevé', 4: 'Très élevé'}, inplace=True)\n",
    "global_data['WorkLifeBalance'].replace({1: 'Mauvais', 2: 'Satisfaisant', 3: 'Très satisfaisant', 4: 'Excellent'}, inplace=True)\n",
    "\n",
    "global_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VII. Preparing data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categorical column\n",
    "categorical_column_data = global_data.select_dtypes(include='object').drop(columns=['Attrition'])\n",
    "categorical_column_name = list(categorical_column_data.columns.values)\n",
    "categorical_column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace categorical data with numerical data\n",
    "global_data_dummy = pd.get_dummies(global_data, columns=categorical_column_name)\n",
    "global_data_dummy['Attrition'] = global_data_dummy['Attrition'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "global_data_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train data with test data\n",
    "X = global_data_dummy.drop('YearsAtCompany', axis=1)\n",
    "y = global_data_dummy['YearsAtCompany']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIII. Model application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "plt.figure(figsize=(60, 40))\n",
    "sns.heatmap(global_data_dummy.corr(), mask=np.triu(np.ones_like(global_data_dummy.corr(), dtype=bool)), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "selector = RFECV(model, step=1, cv=5)\n",
    "selector.fit(X_train, y_train)\n",
    "selected_features = X_train.columns[selector.support_]\n",
    "print(\"Variables sélectionnées :\", selected_features)\n",
    "model.fit(X_train[selected_features], y_train)\n",
    "y_test_pred = model.predict(X_test[selected_features])\n",
    "\n",
    "if hasattr(model, \"intercept_\") and hasattr(model, \"coef_\"):\n",
    "    intercept = model.intercept_\n",
    "    coefficients = model.coef_\n",
    "\n",
    "    print(\"Intercept :\", intercept)\n",
    "    print(\"Coefficients :\", coefficients)\n",
    "else:\n",
    "    print(\"Ce modèle n'expose pas d'intercept ou de coefficients (par exemple, Random Forest).\")\n",
    "\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"MSE :\", mse)\n",
    "print(\"R² :\", r2)\n",
    "\n",
    "X.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
